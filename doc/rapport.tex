\documentclass[journal, a4paper]{IEEEtran}
\usepackage[T1]{fontenc}       % Encodage le plus étendu
\usepackage[utf8]{inputenc}    % Source Unicode en UTF-8
\usepackage{capt-of}  % <---
\usepackage{cuted}    % <===
\usepackage[francais]{babel} % Pour la redaction du document en francais
\usepackage{listings}
\usepackage{mdframed}
\usepackage{multirow}
\usepackage[cyr]{aeguill}
\usepackage[margin=1cm]{geometry} % Adjust margins as needed


\usepackage[
  separate-uncertainty = true,
  multi-part-units = repeat
]{siunitx}
\usepackage{amsmath}
\usepackage{mathtools}% http://ctan.org/pkg/mathtools
\usepackage{float}
\usepackage{graphicx} 
\usepackage{url}    
\usepackage{stfloats} 
\usepackage{amsmath}   

\usepackage{lipsum} % Dummy text


% En-tête et pied de page
\usepackage{lastpage}
\usepackage{placeins}
\usepackage{tabularx}
\usepackage{etoolbox} % for \BeforeBeginEnvironment and \AfterEndEnvironment

\BeforeBeginEnvironment{tabular}{\vspace{0.5cm}} % Add space before the table
\AfterEndEnvironment{tabular}{\vspace{0.5cm}}
\renewcommand{\sectionmark}[1]{\markright{#1}}




% Your document starts here!
\begin{document}


% Define document title and author
\title{Advanced Databases \\\vspace*{20pt} \normalsize Novembre 2024}
\author{Jean-Nicolas Grégoire : 000000 (M-INFO) \\
        Arthur Installe : 000000 (M-INFO) \\
        Moïra Vanderslagmolen : 547486 (M-INFO) \\
        Xu Ze-xuan : 000000 (M-INFO)
        }
\markboth{Advanced Databases}{Advanced Databases}
\date{Novembre 2024}
\maketitle


\section{Introduction}

Stream databases are databases adapted to handle real-time data.
There are two ways to handle data: stream processing and batch processing.
Batch processing process the data by batches, after it has been ?, while stream processing process the data continuously.
It is used in financial transactions, transport logistics, monitoring, etc.

In this report, we want to compare two stream processor: Apache Flink versus Apache Kafka.
Apache Kafka ensure that the data is available for processing while Apache Flink focuses on analyzing real-time datastreams

\section{Foundations}

\subsection{Apache Kafka}
Producer is the client that insert or update the events to the database
Consumer is the client that select the events of the database
A topic is the place where the data is stored. It contains multiples partitions and each partition store a certain numbers of records.

\subsection{Apache Flink}

In Apache Flink, the data sources write to the stream database and the data sinks reads from the database.


\section{Implementation}

\section{Application}

\section{Conclusion}





\end{document}
